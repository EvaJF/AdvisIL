expe0:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 1.0 # width multiplier
  depth_mult : 1.0 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc : 70 # incremental states

expe1:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.1 # width multiplier
  depth_mult : 0.5 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc : 70 # incremental states

expe2:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.1 # width multiplier
  depth_mult : 0.75 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe3:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.1 # width multiplier
  depth_mult : 1.0 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe4:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.2 # width multiplier
  depth_mult : 0.2 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe5:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.2 # width multiplier
  depth_mult : 0.5 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe6:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.2 # width multiplier
  depth_mult : 0.75 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe7:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.2 # width multiplier
  depth_mult : 1.0 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe8:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.5 # width multiplier
  depth_mult : 0.75 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe9:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.5 # width multiplier
  depth_mult : 1.0 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe10:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.75 # width multiplier
  depth_mult : 0.2 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe11:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.75 # width multiplier
  depth_mult : 0.5 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe12:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.75 # width multiplier
  depth_mult : 0.75 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe13:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 0.75 # width multiplier
  depth_mult : 1.0 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe14:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 1.0 # width multiplier
  depth_mult : 0.2 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe15:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 1.0 # width multiplier
  depth_mult : 0.5 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe16:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 1.0 # width multiplier
  depth_mult : 0.75 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe17:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 2.0 # width multiplier
  depth_mult : 0.2 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states

expe18:
  dataset_v : inat100 # for config folder / dataset name + number of classes used in total 
  backbone : shufflenet # base architecture
  width_mult : 2.0 # width multiplier
  depth_mult : 0.5 # depth multiplier
  normalization_dataset_name : inat # as written in the reference normalization file
  last_batch_number : 10 # also S, index
  num_batches : 10 # total number of batches to come
  P : 10 # number of classes per batch
  train_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/train.lst # text file with first line = root_path, folder for dataset, trian100 means no val set
  val_file_path : /your/path/to/AdvisIL/images_list_files/train100/inat/test.lst # caution, val is in fact test here
  algo_name : no_mem_ft # here memoryless fine_tuning
  IL_method : inFT_siw # combined with standardization of initial weights as in Belouadah et al. 
  num_epochs_batch1 : 100 # scratch / first batch
  num_epochs_inc :  70 # incremental states